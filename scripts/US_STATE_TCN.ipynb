{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fafb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tcn import TCN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cab9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tony_data/merged_data.csv\", parse_dates=[\"month\"])\n",
    "df = df.dropna(subset=[\"Unemployment Rate\"])  # ensure target exists\n",
    "\n",
    "# Standardize column names\n",
    "df = df.rename(columns={\n",
    "    \"Unemployment Rate\": \"unemployment_rate\",\n",
    "    \"median_income\": \"median_income\",\n",
    "    \"lfp_rate\": \"lfp_rate\",\n",
    "    \"initial_claims\": \"initial_claims\",\n",
    "    \"population\": \"population\"\n",
    "})\n",
    "\n",
    "feature_cols = [\"median_income\", \"lfp_rate\", \"initial_claims\", \"population\", \"unemployment_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f605eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window):\n",
    "        X.append(data[i:i+window, :-1])\n",
    "        y.append(data[i+window, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def TCN_model(X_shape:tuple, patience=None):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_shape[1], X_shape[2])))\n",
    "    model.add(TCN(nb_filters=64,\n",
    "                  kernel_size=3,\n",
    "                  nb_stacks=1,\n",
    "                  dilations=[1, 2, 4, 8],\n",
    "                  use_layer_norm=True,\n",
    "                  dropout_rate=0.02,\n",
    "                  kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    if patience:\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "        return model, early_stop\n",
    "    else:\n",
    "        return model, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ef5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 14:56:24.479864: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-07-30 14:56:24.479973: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-07-30 14:56:24.479982: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753901784.480341 5247989 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1753901784.481213 5247989 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-07-30 14:56:27.519891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645ms/step\n",
      "✓ Done: Alabama | RMSE: 0.1621 | R²: -23.3098\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987ms/step\n",
      "✓ Done: Alaska | RMSE: 0.1083 | R²: -0.0506\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2a52c4b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2a52c4b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978ms/step\n",
      "✓ Done: Arizona | RMSE: 0.0727 | R²: -1.0480\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 872ms/step\n",
      "✓ Done: Arkansas | RMSE: 0.1467 | R²: -7.6769\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
      "✓ Done: California | RMSE: 0.0818 | R²: 0.1189\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step\n",
      "✓ Done: Colorado | RMSE: 0.0950 | R²: 0.0712\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "✓ Done: Connecticut | RMSE: 0.1111 | R²: 0.2061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step\n",
      "✓ Done: Delaware | RMSE: 0.0646 | R²: -0.1473\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step\n",
      "✓ Done: Florida | RMSE: 0.0806 | R²: -1.1688\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
      "✓ Done: Georgia | RMSE: 0.0657 | R²: -4.3716\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8s/step\n",
      "✓ Done: Hawaii | RMSE: 0.0868 | R²: -1.7604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Initialize ---\n",
    "window = 12\n",
    "rmse_dict = {}\n",
    "r2_dict = {}\n",
    "\n",
    "# --- Loop through states ---\n",
    "for state in df['state'].unique():\n",
    "    try:\n",
    "        # --- 1. Filter state and restrict to pre-2020 ---\n",
    "        df_state = df[df['state'] == state].sort_values('month')\n",
    "        df_state = df_state[df_state['month'] < '2020-01-01']\n",
    "\n",
    "        # --- 2. Skip if insufficient data or NaNs ---\n",
    "        if len(df_state) < window or df_state[feature_cols].isnull().any().any():\n",
    "            continue\n",
    "\n",
    "        # --- 3. Scale and sequence ---\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(df_state[feature_cols])\n",
    "        X, y = create_sequences(scaled, window)\n",
    "\n",
    "        # --- 4. Train-test split (90/10) ---\n",
    "        split1 = int(len(X) * 0.9)\n",
    "        X_train, y_train = X[:split1], y[:split1]\n",
    "        X_test, y_test = X[split1:], y[split1:]\n",
    "\n",
    "        # --- 5. Train model ---\n",
    "        model, early_stop = TCN_model(X_train.shape, patience=3)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=30, batch_size=16,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=[early_stop] if early_stop else None,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # --- 6. Predict and score ---\n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # --- 7. Save to dicts for plotting ---\n",
    "        rmse_dict[state] = rmse\n",
    "        r2_dict[state] = r2\n",
    "\n",
    "        print(f\"✓ Done: {state} | RMSE: {rmse:.4f} | R²: {r2:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error in {state}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ce6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort states by RMSE for consistent ordering\n",
    "states_sorted = sorted(rmse_dict, key=rmse_dict.get)\n",
    "\n",
    "# --- RMSE Plot ---\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(states_sorted, [rmse_dict[s] for s in states_sorted], color='skyblue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"TCN RMSE per State\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- R² Plot ---\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(states_sorted, [r2_dict[s] for s in states_sorted], color='mediumseagreen')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"TCN R² Score per State\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1fe75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# RMSE Plot\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.bar(df_results[\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m], df_results[\u001b[33m'\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m plt.xticks(rotation=\u001b[32m90\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mTCN RMSE per State\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_results' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Create 3D figure ---\n",
    "fig = plt.figure(figsize=(14, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# --- Data ---\n",
    "states = list(rmse_dict.keys())\n",
    "xs = np.arange(len(states))\n",
    "ys = [r2_dict[s] for s in states]\n",
    "zs = [rmse_dict[s] for s in states]\n",
    "\n",
    "# --- 3D scatter plot ---\n",
    "sc = ax.scatter(xs, ys, zs, c=zs, cmap='coolwarm', s=80, depthshade=True)\n",
    "\n",
    "# --- Tick settings ---\n",
    "ax.set_xticks(xs)\n",
    "ax.set_xticklabels(states, rotation=90, fontsize=6, ha='center')\n",
    "ax.tick_params(axis='x', labelsize=6, pad=2)\n",
    "ax.tick_params(axis='y', labelsize=7)\n",
    "ax.tick_params(axis='z', labelsize=7)\n",
    "\n",
    "# --- Axis labels (shift x-label downward using labelpad) ---\n",
    "ax.set_xlabel('State Index', fontsize=9, labelpad=20)\n",
    "ax.set_ylabel('R² Score', fontsize=9, labelpad=10)\n",
    "ax.set_zlabel('RMSE', fontsize=9, labelpad=10)\n",
    "\n",
    "# --- Title and colorbar ---\n",
    "ax.set_title('3D Scatter Plot of Model Performance per State', fontsize=12, pad=20)\n",
    "cbar = plt.colorbar(sc, ax=ax, shrink=0.6, pad=0.1)\n",
    "cbar.set_label('RMSE', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RISE_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
