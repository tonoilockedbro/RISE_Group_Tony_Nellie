{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40fb76cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 15s]\n",
      "val_loss: 0.0040846592746675014\n",
      "\n",
      "Best val_loss So Far: 0.0037168492563068867\n",
      "Total elapsed time: 00h 05m 12s\n",
      "Epoch 1/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0867 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 2/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0050 - mae: 0.0536 - val_loss: 0.0037 - val_mae: 0.0472\n",
      "Epoch 3/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0046 - mae: 0.0507 - val_loss: 0.0037 - val_mae: 0.0467\n",
      "Epoch 4/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - mae: 0.0492 - val_loss: 0.0038 - val_mae: 0.0470\n",
      "Epoch 5/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0039 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0487\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0037 - mae: 0.0469\n",
      "Best validation MAE: 0.0487\n"
     ]
    }
   ],
   "source": [
    "# ── 1. Imports ─────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "\n",
    "# ── 2. Load and Prepare Data ───────────────────────────────────────────────\n",
    "df = pd.read_csv('Tony_data/merged_data.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Select feature columns and target\n",
    "features = ['initial_claims', 'median_income', 'population', 'lfp_rate', 'Unemployment Rate']\n",
    "df = df[features]\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=features)\n",
    "\n",
    "# Create time series samples for LSTM\n",
    "def create_sequences(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data.iloc[i:i+window_size].drop(columns=['Unemployment Rate']).values)\n",
    "        y.append(data.iloc[i+window_size]['Unemployment Rate'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(df_scaled)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "# ── 3. Define the Model Builder Function ───────────────────────────────────\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    \n",
    "    # Tune number of units\n",
    "    hp_units = hp.Int('units', min_value=16, max_value=128, step=16)\n",
    "    model.add(tf.keras.layers.LSTM(units=hp_units, return_sequences=False))\n",
    "    \n",
    "    # Optional dropout\n",
    "    model.add(tf.keras.layers.Dropout(hp.Float('dropout', 0.0, 0.5, step=0.1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1))  # Output: unemployment_rate\n",
    "    \n",
    "    # Tune learning rate\n",
    "    hp_lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_lr),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# ── 4. Run Keras Tuner ─────────────────────────────────────────────────────\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='kt_lstm_dir',\n",
    "    project_name='unemployment_lstm'\n",
    ")\n",
    "\n",
    "# Optional early stopping\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Launch tuning search\n",
    "tuner.search(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[stop_early])\n",
    "\n",
    "# ── 5. Get the Best Model ──────────────────────────────────────────────────\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[stop_early])\n",
    "\n",
    "# ── 6. Evaluate the Model ──────────────────────────────────────────────────\n",
    "val_loss, val_mae = model.evaluate(X_val, y_val)\n",
    "print(f\"Best validation MAE: {val_mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RISE_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
